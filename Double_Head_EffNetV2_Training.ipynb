{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision.models as tvm\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n",
    "from models import dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jakiro(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Jakiro, self).__init__()\n",
    "        model_spec = tvm.efficientnet_v2_s(\"IMAGENET1K_V1\")\n",
    "        self.model_spec = nn.Sequential(model_spec.features,model_spec.avgpool)\n",
    "        \n",
    "        model_phase = tvm.efficientnet_v2_s(\"IMAGENET1K_V1\")\n",
    "        self.model_phase = nn.Sequential(model_phase.features,model_phase.avgpool)\n",
    "        \n",
    "        self.classifier = nn.Linear(1280*2,1,bias=True)\n",
    "    def forward(self, spec, phase):\n",
    "        spec = self.model_spec(spec)\n",
    "        phase = self.model_phase(phase)\n",
    "        concatenated = torch.cat((spec,phase),dim=1)\n",
    "        concatenated =  torch.flatten(concatenated, 1)\n",
    "        \n",
    "        concatenated = self.classifier(concatenated)\n",
    "\n",
    "        return concatenated\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|██████████| 82.7M/82.7M [00:01<00:00, 49.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = Jakiro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,test_dataset,train_loader,test_loader = dataloader.get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'alberta_mall_window=196_vol=35%_gun=1.png' == 'alberta_mall_window=196_vol=35%_gun=1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "opt = optim.AdamW(model.parameters(), lr=0.00001, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt,1,1)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.utils import accuracy, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    loss_meter = AverageMeter()\n",
    "    for idx, (samples,mfcc, targets) in enumerate(train_loader):\n",
    "        num_steps = len(train_loader)\n",
    "        samples = samples.to(device)\n",
    "        mfcc = mfcc.to(device)\n",
    "        \n",
    "        targets = targets.to(device)\n",
    "        targets = targets.view(targets.shape[0], 1).to(dtype=torch.float)\n",
    "\n",
    "        outputs = model(samples,mfcc)\n",
    "        outputs = outputs.view(outputs.shape[0], 1).to(dtype=torch.float)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        loss_meter.update(loss.item(), targets.size(0))\n",
    "\n",
    "    print(\n",
    "                f'Train: [{epoch}/30][{idx}/{num_steps}]\\t'\n",
    "                    f'loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n",
    "    )\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_acc=0\n",
    "        total_samples=0\n",
    "        for idx, (val_images,val_mfcc, val_target) in enumerate(test_loader):\n",
    "            val_target = val_target.to(device)\n",
    "            val_images = val_images.to(device)\n",
    "            val_mfcc = val_mfcc.to(device)\n",
    "            \n",
    "        #         target = target.view(target.shape[0], 1).to(dtype=torch.float)\n",
    "    \n",
    "            val_outputs = model(val_images,val_mfcc)\n",
    "            val_outputs = val_outputs.squeeze()\n",
    "            val_outputs = torch.sigmoid(val_outputs)\n",
    "            acc = (val_target.eq((val_outputs>0.5).to(dtype=torch.long)).cpu().sum())\n",
    "            # print(acc)\n",
    "            total_acc+=acc\n",
    "            total_samples+=val_target.shape[0]\n",
    "    \n",
    "        print(f'Acc: {total_acc/total_samples}\\t')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tvm.efficientnet_v2_s('IMAGENET1K_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.classifier[1] = nn.Linear(1280,1,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.AdamW(model.parameters(), lr=0.00001, weight_decay=1e-5)\n",
    "sch = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt,2,1)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/30][144/145]\tloss 1.1804 (0.5250)\t\n",
      "Acc: 0.82914137840271\t\n",
      "Train: [1/30][144/145]\tloss 0.3081 (0.2985)\t\n",
      "Acc: 0.8529921770095825\t\n",
      "Train: [2/30][144/145]\tloss 0.5784 (0.2602)\t\n",
      "Acc: 0.8026886582374573\t\n",
      "Train: [3/30][144/145]\tloss 0.2315 (0.2545)\t\n",
      "Acc: 0.8499566316604614\t\n",
      "Train: [4/30][144/145]\tloss 0.3352 (0.2160)\t\n",
      "Acc: 0.8590633273124695\t\n",
      "Train: [5/30][144/145]\tloss 0.0649 (0.2012)\t\n",
      "Acc: 0.8568950295448303\t\n",
      "Train: [6/30][144/145]\tloss 0.3942 (0.1661)\t\n",
      "Acc: 0.8616652488708496\t\n",
      "Train: [7/30][144/145]\tloss 0.0201 (0.1348)\t\n",
      "Acc: 0.8464874029159546\t\n",
      "Train: [8/30][144/145]\tloss 0.0125 (0.1155)\t\n",
      "Acc: 0.8633998036384583\t\n",
      "Train: [9/30][144/145]\tloss 0.0688 (0.1125)\t\n",
      "Acc: 0.8547267913818359\t\n",
      "Train: [10/30][144/145]\tloss 0.0422 (0.1252)\t\n",
      "Acc: 0.8425845503807068\t\n",
      "Train: [11/30][144/145]\tloss 3.0765 (0.1201)\t\n",
      "Acc: 0.8456200957298279\t\n",
      "Train: [12/30][144/145]\tloss 0.3364 (0.1049)\t\n",
      "Acc: 0.8525585532188416\t\n",
      "Train: [13/30][144/145]\tloss 0.8659 (0.0959)\t\n",
      "Acc: 0.8499566316604614\t\n",
      "Train: [14/30][144/145]\tloss 0.0070 (0.0908)\t\n",
      "Acc: 0.8651344180107117\t\n",
      "Train: [15/30][144/145]\tloss 0.2790 (0.0583)\t\n",
      "Acc: 0.857762336730957\t\n",
      "Train: [16/30][144/145]\tloss 0.0035 (0.0496)\t\n",
      "Acc: 0.8629661798477173\t\n",
      "Train: [17/30][144/145]\tloss 0.0038 (0.0516)\t\n",
      "Acc: 0.854293167591095\t\n",
      "Train: [18/30][144/145]\tloss 0.0063 (0.0537)\t\n",
      "Acc: 0.8633998036384583\t\n",
      "Train: [19/30][144/145]\tloss 0.0069 (0.0523)\t\n",
      "Acc: 0.8499566316604614\t\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    loss_meter = AverageMeter()\n",
    "    for idx, (samples,mfcc, targets) in enumerate(train_loader):\n",
    "        num_steps = len(train_loader)\n",
    "        samples = samples.to(device)        \n",
    "        targets = targets.to(device)\n",
    "        targets = targets.view(targets.shape[0], 1).to(dtype=torch.float)\n",
    "\n",
    "        outputs = model(samples)\n",
    "        outputs = outputs.view(outputs.shape[0], 1).to(dtype=torch.float)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        loss_meter.update(loss.item(), targets.size(0))\n",
    "\n",
    "    print(\n",
    "                f'Train: [{epoch}/30][{idx}/{num_steps}]\\t'\n",
    "                    f'loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n",
    "    )\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_acc=0\n",
    "        total_samples=0\n",
    "        for idx, (val_images,val_mfcc, val_target) in enumerate(test_loader):\n",
    "            val_target = val_target.to(device)\n",
    "            val_images = val_images.to(device)\n",
    "            \n",
    "        #         target = target.view(target.shape[0], 1).to(dtype=torch.float)\n",
    "    \n",
    "            val_outputs = model(val_images)\n",
    "            val_outputs = val_outputs.squeeze()\n",
    "            val_outputs = torch.sigmoid(val_outputs)\n",
    "            acc = (val_target.eq((val_outputs>0.5).to(dtype=torch.long)).cpu().sum())\n",
    "            # print(acc)\n",
    "            total_acc+=acc\n",
    "            total_samples+=val_target.shape[0]\n",
    "    \n",
    "        print(f'Acc: {total_acc/total_samples}\\t')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
